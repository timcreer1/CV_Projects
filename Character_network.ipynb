{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1cddaVJ3uhaezMKZP19y0zJZZohHAMemT","authorship_tag":"ABX9TyNJrFOb1L7GtolRDdBezOo2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["\n","# Character Network\n"],"metadata":{"id":"__B--D5trjWN"}},{"cell_type":"code","source":["#imports\n","import glob2\n","import pandas as pd\n","import spacy\n","import re\n","import nltk\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","import ssl\n","nltk.download('punkt')\n","import json\n","!pip install pyvis"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SWlhUKBLtdB4","executionInfo":{"status":"ok","timestamp":1724048423953,"user_tz":-600,"elapsed":21730,"user":{"displayName":"Tim","userId":"14787078968151416742"}},"outputId":"c1468892-e255-4ffe-c319-10b6a11a0d10"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Collecting pyvis\n","  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis) (7.34.0)\n","Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.1.4)\n","Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.2.2)\n","Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.3)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (71.0.4)\n","Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n","  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (3.0.47)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9.6->pyvis) (2.1.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.13)\n","Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","Installing collected packages: jedi, pyvis\n","Successfully installed jedi-0.19.1 pyvis-0.3.2\n"]}]},{"cell_type":"code","source":["# Extracting subtitles & characters from the saved files\n","subtitles_paths = sorted(glob2.glob(\"/content/drive/MyDrive/Colab Notebooks/2024 Data Science Projects/Naruto/Subtitles/*.ass\"))\n","file_path = '/content/drive/MyDrive/Colab Notebooks/2024 Data Science Projects/Naruto/characters.json'\n","\n","with open(file_path, 'r') as file:\n","    character_names = [item['character'] for item in json.load(file)]"],"metadata":{"id":"_-XfFzvKv3q6","executionInfo":{"status":"ok","timestamp":1724048529253,"user_tz":-600,"elapsed":2896,"user":{"displayName":"Tim","userId":"14787078968151416742"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Reading the file data (can't use pandas as commas in required text cause issue with parsing)\n","scripts = []\n","episode_num = []\n","for path in subtitles_paths:\n","    with open(path, 'r', encoding='utf-8') as file:\n","        lines = file.readlines()\n","\n","        # Skip the first 15 lines\n","        lines = lines[15:]\n","\n","        # Loop over each line, splitting by comma and taking the 9th column\n","        rows = [line.split(',')[9] for line in lines if len(line.split(',')) > 9]\n","\n","        # Remove new line notation and join lines into a single script\n","        rows = [line.replace(\"\\\\N\", ' ') for line in rows]\n","        rows = [line.replace(\"{\\i1}\", ' ') for line in rows]\n","        rows = [line.replace(\"{\\i0}\", ' ') for line in rows]\n","        script = \" \".join(rows)\n","\n","    # Extract the episode number from the filename\n","    filename = path.split('/')[-1]\n","    episode = int(filename.split('-')[1].split()[0].strip())\n","    scripts.append(script)\n","    episode_num.append(episode)\n","\n","# Create a DataFrame from the lists\n","df = pd.DataFrame({'episode': episode_num, 'script': scripts})"],"metadata":{"id":"xb2KZCzt8d5f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Clean the character names by removing brackets and last names\n","cleaned_character_names = set()\n","for name in character_names:\n","    clean_name = re.sub(r'\\s*\\(.*?\\)\\s*', '', name).strip()\n","    first_name = clean_name.split()[0]\n","    if len(first_name) > 1:\n","        cleaned_character_names.add(first_name)\n","\n","cleaned_character_names = list(cleaned_character_names)\n","\n","df = pd.DataFrame({'episode': episode_num, 'script': scripts})\n","# Function to find character names in the script\n","def get_names(script):\n","    script_sentences = sent_tokenize(script)\n","    names_output = []\n","    # Looping over each sentence to find character names\n","    for sentence in script_sentences:\n","        sentence_tokens = word_tokenize(sentence)\n","        sentence_names = [character for character in cleaned_character_names if character in sentence_tokens]\n","        names_output.append(sentence_names if sentence_names else [])\n","    return names_output\n","\n","# Apply the function only to the first episode\n","new_df = pd.DataFrame({'script': [df.loc[0, 'script']], 'names': [get_names(df.loc[0, 'script'])]})\n","new_df"],"metadata":{"id":"5ZeAigbp-570"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Applying function to df\n","df1 = df\n","df1['names'] = df1['script'].apply(get_names)\n","df.head()"],"metadata":{"id":"9ftl1wlrwcna"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Getting list of any time 2 characters appear within 10 sentences\n","window = 10\n","entity_relationship = []\n","for row in df1['names']:\n","    previous_entities_in_window = []\n","\n","    #looping over each sentence in a row, taking only previous 10\n","    for sentence in row:\n","        previous_entities_in_window.append(sentence)\n","        previous_entities_in_window = previous_entities_in_window[-window:]\n","        #flatten the list of list into one row\n","        previous_entities_flattened = sum(previous_entities_in_window, [])\n","        #loop over each entity in the current sentence and previous 10\n","        for entity in sentence:\n","            for entity_in_window in previous_entities_flattened:\n","                if entity != entity_in_window:\n","                    entity_rel = sorted([entity, entity_in_window])\n","                    entity_relationship.append(entity_rel)\n","\n","#create a df with entity relationships\n","relationship_df = pd.DataFrame({'value':entity_relationship})"],"metadata":{"id":"B441VOnlweCx","executionInfo":{"status":"aborted","timestamp":1724048423954,"user_tz":-600,"elapsed":8,"user":{"displayName":"Tim","userId":"14787078968151416742"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#returns the first element of the list\n","relationship_df['source'] = relationship_df['value'].apply(lambda x: x[0])\n","#returns the second element of the list\n","relationship_df['target'] = relationship_df['value'].apply(lambda x: x[1])\n","#groupby and count\n","relationship_df = relationship_df.groupby(['source','target']).count().reset_index()\n","relationship_df = relationship_df.sort_values('value',ascending=False)"],"metadata":{"id":"PEdcCCXAwjiD","executionInfo":{"status":"aborted","timestamp":1724048423954,"user_tz":-600,"elapsed":7,"user":{"displayName":"Tim","userId":"14787078968151416742"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["relationship_df.head()"],"metadata":{"id":"L2xDMEMdHeZG","executionInfo":{"status":"aborted","timestamp":1724048423954,"user_tz":-600,"elapsed":7,"user":{"displayName":"Tim","userId":"14787078968151416742"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#taking only the first 200 relationships\n","relationship_df = relationship_df.head(200)"],"metadata":{"id":"0Rz72aL36rOd","executionInfo":{"status":"aborted","timestamp":1724048423954,"user_tz":-600,"elapsed":7,"user":{"displayName":"Tim","userId":"14787078968151416742"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#creating a network map\n","import networkx as nx\n","G = nx.from_pandas_edgelist(relationship_df,\n","                            source = \"source\",\n","                            target = \"target\",\n","                            edge_attr = \"value\",\n","                            create_using = nx.Graph())"],"metadata":{"id":"AChLoQdLCIhL","executionInfo":{"status":"aborted","timestamp":1724048423954,"user_tz":-600,"elapsed":7,"user":{"displayName":"Tim","userId":"14787078968151416742"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#showing the network map\n","import matplotlib.pyplot as plt\n","plt.figure(figsize=(10,10))\n","pos = nx.kamada_kawai_layout(G)\n","nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos = pos)\n","plt.show()"],"metadata":{"id":"LJQN9vVWCN_n","executionInfo":{"status":"aborted","timestamp":1724048423955,"user_tz":-600,"elapsed":8,"user":{"displayName":"Tim","userId":"14787078968151416742"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import the necessary libraries\n","from pyvis.network import Network\n","import networkx as nx\n","from IPython.core.display import display, HTML\n","\n","# Create a Pyvis Network object with cdn_resources set to 'in_line'\n","net = Network(notebook=True, width=\"1000px\", height=\"700px\", bgcolor='#222222', font_color='white', cdn_resources='in_line')\n","\n","# Calculate node degrees\n","node_degree = dict(G.degree)\n","\n","# Set node size attribute\n","nx.set_node_attributes(G, node_degree, 'size')\n","\n","# Add nodes and edges from the NetworkX graph to the Pyvis Network\n","net.from_nx(G)\n","\n","# Generate and save the network visualization to an HTML file\n","net.show(\"naruto.html\")\n","\n","# Display the generated HTML file inline using an iframe\n","display(HTML('naruto.html'))"],"metadata":{"id":"9NjK3a07Cg9o","executionInfo":{"status":"aborted","timestamp":1724048423955,"user_tz":-600,"elapsed":8,"user":{"displayName":"Tim","userId":"14787078968151416742"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#"],"metadata":{"id":"xry_-pvWr5e1"}}]}